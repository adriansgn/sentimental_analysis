{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c0fcad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "import scipy\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619be960",
   "metadata": {},
   "source": [
    "### Preparing to reproduce negative category values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c39cfe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04b51476",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"twitter_cleaned.csv\")\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4441bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index() #shuffling data in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7433b1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "negative     7748\n",
       "neutral     22255\n",
       "positive    19672\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['label']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98181edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25286</td>\n",
       "      <td>negative</td>\n",
       "      <td>misleading headline but may this divided ancho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17637</td>\n",
       "      <td>negative</td>\n",
       "      <td>eid holiday completely compromised by guest am...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>48750</td>\n",
       "      <td>negative</td>\n",
       "      <td>extremely jealous of owains day off tomorrow i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>49416</td>\n",
       "      <td>negative</td>\n",
       "      <td>why every time twitter email me saying we foun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>21588</td>\n",
       "      <td>negative</td>\n",
       "      <td>also i see dustin johnson is leading after the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49619</th>\n",
       "      <td>1791</td>\n",
       "      <td>negative</td>\n",
       "      <td>pritishnandy yakub arranged fund for the blast...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49620</th>\n",
       "      <td>11761</td>\n",
       "      <td>negative</td>\n",
       "      <td>well done chris evans i did not think it wa po...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49634</th>\n",
       "      <td>13455</td>\n",
       "      <td>negative</td>\n",
       "      <td>i never thought kanye west announcing a crack ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49656</th>\n",
       "      <td>6660</td>\n",
       "      <td>negative</td>\n",
       "      <td>i will be so good at the military your head wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49674</th>\n",
       "      <td>18700</td>\n",
       "      <td>negative</td>\n",
       "      <td>talk about post holiday blue second of george ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7748 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     label                                            message  \\\n",
       "1      25286  negative  misleading headline but may this divided ancho...   \n",
       "12     17637  negative  eid holiday completely compromised by guest am...   \n",
       "16     48750  negative  extremely jealous of owains day off tomorrow i...   \n",
       "19     49416  negative  why every time twitter email me saying we foun...   \n",
       "23     21588  negative  also i see dustin johnson is leading after the...   \n",
       "...      ...       ...                                                ...   \n",
       "49619   1791  negative  pritishnandy yakub arranged fund for the blast...   \n",
       "49620  11761  negative  well done chris evans i did not think it wa po...   \n",
       "49634  13455  negative  i never thought kanye west announcing a crack ...   \n",
       "49656   6660  negative  i will be so good at the military your head wi...   \n",
       "49674  18700  negative  talk about post holiday blue second of george ...   \n",
       "\n",
       "       category  \n",
       "1             0  \n",
       "12            0  \n",
       "16            0  \n",
       "19            0  \n",
       "23            0  \n",
       "...         ...  \n",
       "49619         0  \n",
       "49620         0  \n",
       "49634         0  \n",
       "49656         0  \n",
       "49674         0  \n",
       "\n",
       "[7748 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_nega = df[df[\"category\"]==0] \n",
    "df_class_nega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ab774e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = load(\"tfidf_vectorizer.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94a72405",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_negative = tfidf_model.transform(df_class_nega['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b0d17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, num_features=400, num_dim=2000):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        \n",
    "        self.num_features = num_features\n",
    "        self.num_dim = num_dim\n",
    "        \n",
    "        self.encoder_layer_1 = nn.Linear(in_features=self.num_dim, out_features=800)\n",
    "        self.encoder_layer_2 = nn.Linear(in_features=800, out_features=(self.num_features * 2))\n",
    "        \n",
    "        self.decoder_layer_1 = nn.Linear(in_features=self.num_features, out_features=800)\n",
    "        self.decoder_layer_2 = nn.Linear(in_features=800, out_features=self.num_dim)\n",
    "        \n",
    "        self.relu = nn.ReLU() # hidden layers\n",
    "        self.sigmoid = nn.Sigmoid() # output layer\n",
    "        \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        :param mu: mean from the encoder's latent space\n",
    "        :param log_var: log variance from the encoder's latent space\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5*log_var) # standard deviation\n",
    "        eps = torch.randn_like(std)  # `randn_like` as we need the same size\n",
    "        sample = mu + (eps * std)    # sampling as if coming from the input space\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def encode(self, x):\n",
    "        # encoding\n",
    "        #x = F.relu(self.encoder_layer_1(x))\n",
    "        x = self.encoder_layer_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.encoder_layer_2(x).view(-1, 2, self.num_features)\n",
    "        \n",
    "        # get `mu` and `log_var`\n",
    "        mu = x[:, 0, :] # the first feature values as mean\n",
    "        log_var = x[:, 1, :] # the other feature values as variance\n",
    "        \n",
    "        # get the latent vector through reparameterization\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        \n",
    "        return z, mu, log_var\n",
    "    \n",
    "    def decode(self, z, mu, log_var):\n",
    "        # decoding\n",
    "        #x = F.relu(self.decoder_layer_1(z))\n",
    "        x = self.decoder_layer_1(z)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        #reconstruction = torch.sigmoid(self.decoder_layer_2(x))\n",
    "        reconstruction = self.decoder_layer_2(x)\n",
    "        reconstruction = self.sigmoid(reconstruction)\n",
    "        \n",
    "        return reconstruction, mu, log_var\n",
    "    \n",
    "    # Utility function to generate new data based on:\n",
    "    # mu: The average that you want to have (should be the same size as num_features)\n",
    "    # log_var: The variance that you want to have (should be the same size as num_features)\n",
    "    def sample(self, mu, log_var):\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        reconstruction, mu, log_var = self.decode(z, mu, log_var)\n",
    "        \n",
    "        return reconstruction\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        z, mu, log_var = self.encode(x)\n",
    "        reconstruction, mu, log_var = self.decode(z, mu, log_var)\n",
    "        \n",
    "        return reconstruction, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a596c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencoderDataset(Dataset):\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    # Requires you to return data as a pair of _x, _y\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.x[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3461cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_loss(bce_loss, mu, logvar):\n",
    "    \"\"\"\n",
    "    This function will add the reconstruction loss (BCELoss) and the \n",
    "    KL-Divergence.\n",
    "    KL-Divergence = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    :param bce_loss: recontruction loss\n",
    "    :param mu: the mean from the latent vector\n",
    "    :param logvar: log variance from the latent vector\n",
    "    \"\"\"\n",
    "    BCE = bce_loss \n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "762ee911",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 400\n",
    "model = VariationalAutoencoder(num_features=num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1253bae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25893e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(loader, model, optimizer, loss_fn, batch_size):\n",
    "    loop = tqdm(loader)\n",
    "    \n",
    "    count = 0\n",
    "    ave_loss = 0.00\n",
    "    \n",
    "    # Loop per batch\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        reconstruction, mu, logvar = model.forward(data)\n",
    "        \n",
    "        loss = loss_fn(reconstruction, targets)\n",
    "        \n",
    "        loss = final_loss(loss, mu, logvar)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "        ave_loss += loss.item()\n",
    "        count += 1\n",
    "        \n",
    "    ave_loss = ave_loss / count\n",
    "    \n",
    "    return ave_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0151f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(scipy.sparse.csr_matrix.todense(mat_negative)).float()\n",
    "\n",
    "# use Dataloader for Autoencoder \n",
    "custom_dataset = AutoencoderDataset(x)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    custom_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "946b313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:44<00:00, 10.95it/s, loss=0.0134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.05047375777371458\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:41<00:00, 11.58it/s, loss=0.0132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.012379619227626275\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:49<00:00,  9.71it/s, loss=0.0132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011702482388882907\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:51<00:00,  9.34it/s, loss=0.0131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011650008293464012\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:52<00:00,  9.17it/s, loss=0.0131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.01166474326638524\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:52<00:00,  9.22it/s, loss=0.0132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011695637363825262\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:56<00:00,  8.59it/s, loss=0.0135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011735415182162806\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:54<00:00,  8.87it/s, loss=0.0131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011775967665016651\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:52<00:00,  9.30it/s, loss=0.0134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011825546624196558\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:55<00:00,  8.71it/s, loss=0.0134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011864930710073598\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:49<00:00,  9.70it/s, loss=0.0135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011905049240773485\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:54<00:00,  8.93it/s, loss=0.0136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011935234271450755\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:53<00:00,  8.99it/s, loss=0.013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011938508991728124\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:55<00:00,  8.79it/s, loss=0.0138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011952210968533128\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:52<00:00,  9.26it/s, loss=0.0132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011975367935662416\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:51<00:00,  9.49it/s, loss=0.0133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.011973863323555165\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:51<00:00,  9.41it/s, loss=0.0142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.012005700443669692\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:48<00:00,  9.90it/s, loss=0.0133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.012014317191830002\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:48<00:00,  9.91it/s, loss=0.0135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.012009223099298699\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:47<00:00, 10.31it/s, loss=0.0139]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 0.012022775171574244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    \n",
    "    ave_loss = train_fn(\n",
    "        train_loader,\n",
    "        model,\n",
    "        optimizer,\n",
    "        loss_fn,\n",
    "        batch_size\n",
    "    )\n",
    "    \n",
    "    losses.append(ave_loss)\n",
    "    \n",
    "    print(\"Ave Loss: {}\".format(ave_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6fe0b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"negative_autoencoder.joblib\", \"wb+\") as filename:\n",
    "    joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d5952a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASAGUN\\AppData\\Local\\Temp\\ipykernel_21696\\2852482480.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "  sampled_mu = torch.Tensor([np.zeros(num_features)])\n"
     ]
    }
   ],
   "source": [
    "# Create a vector of zero tensors representing 0 average per num_feature (right in the middle of the dist)\n",
    "sampled_mu = torch.Tensor([np.zeros(num_features)])\n",
    "\n",
    "# Create a vector of zero tensors representing 0 standard deviations away from the mean to create variations\n",
    "# Change this is you want to sample away from the mean to create \"off-quality\" data\n",
    "sampled_logvar = torch.Tensor([np.zeros(num_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a563d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = []\n",
    "for i in range(15000):\n",
    "    reconstruction = model.sample(sampled_mu, sampled_logvar)\n",
    "    reconstructed = reconstruction[0].detach().cpu().numpy()\n",
    "    data_gen.append(reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfd821e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_negative = pd.DataFrame(data_gen, columns=[i for i in range(2000)])\n",
    "# df_classM_gen.rename(columns={32:\"1_B\", 33:\"1_M\"},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4a53928",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_negative['category'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8419a4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_neutral = tfidf_model.transform(df[df['category']==1]['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bbb1fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_neutral = pd.DataFrame(scipy.sparse.csr_matrix.todense(mat_neutral))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c698acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_neutral['category'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10815cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_positive = tfidf_model.transform(df[df['category']==2]['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6efe1e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_positive = pd.DataFrame(scipy.sparse.csr_matrix.todense(mat_positive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad6502ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_positive['category'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6bceadbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([mat_negative, mat_neutral, mat_positive], axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e4f4716",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('twitter_class.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "756114ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "0    15000\n",
       "1    22255\n",
       "2    19672\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.groupby(['category']).size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
